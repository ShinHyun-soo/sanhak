import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile
import pandas as pd # pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€

# MediaPipe Pose ëª¨ë¸ ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

def calculate_distance(point1, point2):
    """ë‘ ì  ì‚¬ì´ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    return np.sqrt((point1.x - point2.x)**2 + (point1.y - point2.y)**2 + (point1.z - point2.z)**2)

def process_frame(frame, pose_model):
    """ë‹¨ì¼ í”„ë ˆì„ì„ ì²˜ë¦¬í•˜ì—¬ ë³´í­ì„ ê³„ì‚°í•˜ê³  ëœë“œë§ˆí¬ë¥¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜"""
    
    # ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ í”„ë ˆì„ í¬ê¸° ì¡°ì ˆ ë° ìƒ‰ìƒ ë³€í™˜
    h, w, _ = frame.shape
    frame_small = cv2.resize(frame, (int(w/2), int(h/2)))
    image = cv2.cvtColor(frame_small, cv2.COLOR_BGR2RGB)
    
    image.flags.writeable = False
    results = pose_model.process(image)
    image.flags.writeable = True
    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

    stride_in_meters = None
    
    if results.pose_landmarks:
        landmarks = results.pose_landmarks.landmark
        
        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        
        left_ankle = landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value]
        right_ankle = landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value]

        if left_ankle.visibility > 0.5 and right_ankle.visibility > 0.5:
            stride_dist_pixels = calculate_distance(left_ankle, right_ankle)
            
            left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]
            right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value]
            hip_dist_pixels = calculate_distance(left_hip, right_hip)

            if hip_dist_pixels > 0.05:
                scale = 0.5 / hip_dist_pixels 
                stride_in_meters = stride_dist_pixels * scale
                
                cv2.putText(image, f"Stride: {stride_in_meters:.2f} m", (30, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2, cv2.LINE_AA)
                            
    return image, stride_in_meters

# --- Streamlit UI ì„¤ì • ---
st.set_page_config(page_title="ë³´í­ ë¹„êµ ë¶„ì„ê¸°", page_icon="ğŸ“Š", layout="wide")

st.title("ğŸ“Š ë™ì˜ìƒ ë³´í­ ë¹„êµ ë¶„ì„ê¸°")
st.write("ë‘ ê°œì˜ ê±·ëŠ” ë™ì˜ìƒì„ ì—…ë¡œë“œí•˜ì—¬ ë³´í­ ë³€í™”ë¥¼ í•˜ë‚˜ì˜ ê·¸ë˜í”„ì—ì„œ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.")
st.info("ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ **ì¸¡ë©´ì—ì„œ ì´¬ì˜ë˜ê³ , ì „ì‹ ì´ ì˜ ë³´ì´ëŠ”** ë™ì˜ìƒì„ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.", icon="ğŸ’¡")

col1, col2 = st.columns(2)

with col1:
    st.header("ë™ì˜ìƒ 1")
    uploaded_file1 = st.file_uploader("ì²« ë²ˆì§¸ ë™ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["mp4", "mov", "avi"], key="file1")

with col2:
    st.header("ë™ì˜ìƒ 2")
    uploaded_file2 = st.file_uploader("ë‘ ë²ˆì§¸ ë™ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["mp4", "mov", "avi"], key="file2")

if st.button("ë‘ ì˜ìƒ ë¶„ì„ ì‹œì‘í•˜ê¸°", use_container_width=True):
    if uploaded_file1 and uploaded_file2:
        
        pose1 = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)
        pose2 = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)

        tfile1 = tempfile.NamedTemporaryFile(delete=False)
        tfile1.write(uploaded_file1.read())
        video_path1 = tfile1.name

        tfile2 = tempfile.NamedTemporaryFile(delete=False)
        tfile2.write(uploaded_file2.read())
        video_path2 = tfile2.name

        cap1 = cv2.VideoCapture(video_path1)
        cap2 = cv2.VideoCapture(video_path2)
        
        with col1:
            stframe1 = st.empty()
        with col2:
            stframe2 = st.empty()
            
        # í†µí•© ì°¨íŠ¸ ì˜ì—­ì„ ì»¬ëŸ¼ ë°”ê¹¥ì— ìƒì„±
        st.header("ë³´í­ ë³€í™” ë¹„êµ ê·¸ë˜í”„")
        chart_spot = st.empty()
            
        stride_data1, stride_data2 = [], []
        
        progress_bar = st.progress(0)
        status_text = st.empty()

        max_frames = max(int(cap1.get(cv2.CAP_PROP_FRAME_COUNT)), int(cap2.get(cv2.CAP_PROP_FRAME_COUNT)))
        frame_count = 0

        while True:
            ret1, frame1 = cap1.read()
            ret2, frame2 = cap2.read()

            if not ret1 and not ret2:
                break
            
            frame_count +=1

            if ret1:
                processed_frame1, stride1 = process_frame(frame1, pose1)
                stframe1.image(processed_frame1, channels="BGR", use_column_width=True)
                stride_data1.append(stride1 if stride1 is not None else np.nan) # ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° NaN ì¶”ê°€

            if ret2:
                processed_frame2, stride2 = process_frame(frame2, pose2)
                stframe2.image(processed_frame2, channels="BGR", use_column_width=True)
                stride_data2.append(stride2 if stride2 is not None else np.nan) # ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° NaN ì¶”ê°€

            # --- ì°¨íŠ¸ ì—…ë°ì´íŠ¸ ë¡œì§ ë³€ê²½ ---
            # ë‘ ë°ì´í„°ì˜ ê¸¸ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•´ ì§§ì€ ìª½ì— NaN ì¶”ê°€
            len1, len2 = len(stride_data1), len(stride_data2)
            max_len = max(len1, len2)
            
            # pandas ë°ì´í„°í”„ë ˆì„ ìƒì„±
            chart_data = pd.DataFrame({
                'ë™ì˜ìƒ 1': stride_data1 + [np.nan] * (max_len - len1),
                'ë™ì˜ìƒ 2': stride_data2 + [np.nan] * (max_len - len2),
            })
            
            # í†µí•© ì°¨íŠ¸ ì—…ë°ì´íŠ¸
            chart_spot.line_chart(chart_data)

            progress = frame_count / max_frames
            progress_bar.progress(min(progress, 1.0))
            status_text.text(f"ë¶„ì„ ì§„í–‰ë¥ : {int(min(progress, 1.0) * 100)}%")

        cap1.release()
        cap2.release()
        pose1.close()
        pose2.close()
        
        status_text.success("ë¶„ì„ ì™„ë£Œ!")
        st.balloons()
        
    else:
        st.warning("âš ï¸ ë‘ ê°œì˜ ë™ì˜ìƒì„ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")